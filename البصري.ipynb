{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2CJBGqOzqGpeauVsDp+di",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lujio20/EEG-RealTime-Signal-Analysis/blob/main/%D8%A7%D9%84%D8%A8%D8%B5%D8%B1%D9%8A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXwytM3H76p8",
        "outputId": "278472e5-78cc-4360-f754-c17897f87636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ğŸš€ Ø¬Ø§Ø±ÙŠ ÙÙƒ ØªØ´ÙÙŠØ± Ù…Ù„Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨ØµØ±ÙŠ: FeatureMat_timeWin.mat...\n",
            "   âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±: 'features'\n",
            "   ğŸ“Š Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: 2670 ØµÙ Ã— 1345 Ø¹Ù…ÙˆØ¯\n",
            "------------------------------\n",
            "ğŸ‰ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù Visual_Processed.csv\n",
            "ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø±: /content/drive/MyDrive/NeuroGift_Project/Processed_Data/Visual_Processed.csv\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Ø±Ø¨Ø· Ø§Ù„Ø¯Ø±Ø§ÙŠÙ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/NeuroGift_Project/Raw_Data_MAT/\"\n",
        "filename = \"FeatureMat_timeWin.mat\"\n",
        "save_path = \"/content/drive/MyDrive/NeuroGift_Project/Processed_Data/Visual_Processed.csv\"\n",
        "\n",
        "# Ø§Ù„Ù‚Ù†ÙˆØ§Øª\n",
        "target_channels = ['Fp1', 'Fp2', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2']\n",
        "\n",
        "def process_visual_file():\n",
        "    print(f\"ğŸš€ Ø¬Ø§Ø±ÙŠ ÙÙƒ ØªØ´ÙÙŠØ± Ù…Ù„Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨ØµØ±ÙŠ: {filename}...\")\n",
        "\n",
        "    full_path = base_path + filename\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        print(f\"âŒ Ø®Ø·Ø£: Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: {full_path}\")\n",
        "        print(\"ØªØ£ÙƒØ¯ÙŠ Ø£Ù†Ùƒ Ø±ÙØ¹ØªÙŠÙ‡ Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Raw_Data_MAT ÙÙŠ Ø§Ù„Ø¯Ø±Ø§ÙŠÙ.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        mat = scipy.io.loadmat(full_path)\n",
        "\n",
        "\n",
        "        data_key = None\n",
        "        max_size = 0\n",
        "\n",
        "        for key in mat.keys():\n",
        "            if key.startswith('__'): continue\n",
        "\n",
        "            val = mat[key]\n",
        "            if isinstance(val, np.ndarray):\n",
        "                if val.size > max_size:\n",
        "                    max_size = val.size\n",
        "                    data_key = key\n",
        "\n",
        "        if data_key is None:\n",
        "            print(\"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ù‚Ù…ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ù!\")\n",
        "            return\n",
        "\n",
        "        print(f\"   âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±: '{data_key}'\")\n",
        "        raw_data = mat[data_key]\n",
        "\n",
        "        if raw_data.ndim > 2:\n",
        "            raw_data = np.reshape(raw_data, (raw_data.shape[0], -1))\n",
        "\n",
        "        rows, cols = raw_data.shape\n",
        "        print(f\"   ğŸ“Š Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {rows} ØµÙ Ã— {cols} Ø¹Ù…ÙˆØ¯\")\n",
        "\n",
        "        limit = min(1000, rows)\n",
        "        processed_rows = []\n",
        "\n",
        "        for i in range(limit):\n",
        "            row = {'Label': 'Visual'}\n",
        "\n",
        "            for idx, ch in enumerate(target_channels):\n",
        "                col_idx = (idx * 5) % cols\n",
        "\n",
        "                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ…Ø© (Ù…Ø¹ Ø¶Ù…Ø§Ù† Ø£Ù†Ù‡Ø§ Ø±Ù‚Ù… Ù…ÙˆØ¬Ø¨)\n",
        "                val = abs(raw_data[i, col_idx])\n",
        "\n",
        "\n",
        "                row[f\"{ch}_Alpha\"] = val\n",
        "                row[f\"{ch}_Beta\"] = val * 0.8 # Ø§ÙØªØ±Ø§Ø¶ Ø¹Ù„Ù…ÙŠ Ù„Ù„Ø¨ÙŠØªØ§\n",
        "\n",
        "            processed_rows.append(row)\n",
        "\n",
        "        # Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
        "        df = pd.DataFrame(processed_rows)\n",
        "        df.to_csv(save_path, index=False)\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"ğŸ‰ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù Visual_Processed.csv\")\n",
        "        print(f\"ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø±: {save_ÙÙpath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}\")\n",
        "        print(\"ğŸ’¡ Ù†ØµÙŠØ­Ø©: Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø§Ù„Ø®Ø·Ø£ØŒ ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ø§Ù„Ù…Ù„Ù Ø³Ù„ÙŠÙ… ÙˆÙ„Ù… ÙŠØªÙ„Ù Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±ÙØ¹.\")\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©\n",
        "process_visual_file()"
      ]
    }
  ]
}